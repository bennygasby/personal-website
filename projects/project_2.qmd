---
title: "Bias in AI Research Project"
format: html
about:
  template: jolla
  image: pic_2.jpg
toc: false
---

### Independent Research supervised by UCLA Faculty 
data analytics, *October 2024 - current*

### *Research Overview*

I am conducting research to evaluate decision-making processes in law enforcement and artificial intelligence, with a focus on understanding potential biases. This study aims to compare how law enforcement professionals and an AI system analyze fictional criminal case files, assessing decision accuracy, confidence, and underlying biases while maintaining a controlled and neutral study environment.

Participants, including law enforcement professionals such as police officers and detectives, review anonymized fictional case files featuring varied suspect demographics. Simultaneously, a specialized AI system analyzes the same cases under identical conditions. Both human participants and the AI are tasked with identifying the most likely suspect and assigning confidence scores to their decisions, with all case files randomized to minimize order effects.

To ensure unbiased behavior, the study conceals its focus on bias, presenting itself as an evaluation of decision-making tools and strategies. Statistical analysis will compare human and AI performance, focusing on differences in suspect selection and confidence while examining how factors such as demographic variables influence decisions.

This research explores the broader implications of integrating AI in decision-making processes, particularly in high-stakes fields like law enforcement. By identifying patterns of bias and assessing the potential of AI to reduce such biases, this study aims to contribute to fairer and more accurate decision-making frameworks, bridging the gap between human expertise and technological innovation.